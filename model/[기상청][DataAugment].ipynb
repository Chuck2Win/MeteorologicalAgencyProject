{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[기상청][DataAugment].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BszE_y5aV38K",
        "outputId": "de753246-7764-4991-d4f7-6c01fa91e5d3"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install kobert-transformers\n",
        "! pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=aea61eba5fd871f61b1c3ec082e39349e3c647a107ccf38dda8c9ff48f283637\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n",
            "Collecting kobert-transformers\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/6d/f4e21513c1f26cacd68c144a428ccaa90dd92d85985e878976ebbaf06624/kobert_transformers-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: transformers>=2.9.1 in /usr/local/lib/python3.6/dist-packages (from kobert-transformers) (4.3.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from kobert-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (20.9)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.1->kobert-transformers) (0.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->kobert-transformers) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->kobert-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=2.9.1->kobert-transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.9.1->kobert-transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.9.1->kobert-transformers) (2.10)\n",
            "Installing collected packages: kobert-transformers\n",
            "Successfully installed kobert-transformers-0.4.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: tweepy, JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n",
            "Collecting kss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/e2/43ac92280810437a552111db85a0379dfaa5ca8ccd81d27a547e9091e5d5/kss-2.5.0-py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.0MB/s \n",
            "\u001b[?25hInstalling collected packages: kss\n",
            "Successfully installed kss-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcaf5rXSDXgL",
        "outputId": "42f3b97d-6586-418d-b691-77e083c92ce8"
      },
      "source": [
        "from tokenizers import Tokenizer\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import torchtext\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "import pandas as pd\r\n",
        "from pandas import DataFrame as df\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from tqdm import tqdm\r\n",
        "import time\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "os.chdir('./gdrive/My Drive/기상청')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6nTLYn8Yxu8"
      },
      "source": [
        "#  Data Load\r\n",
        "train_data = pd.read_pickle('./data/train_data')\r\n",
        "val_data = pd.read_pickle('./data/val_data')\r\n",
        "test_data = pd.read_pickle('./data/test_data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW-uJGZPeJl7"
      },
      "source": [
        "# 숫자는 [NUM]으로 치환\r\n",
        "train_data['Total']=train_data['Total'].apply(lambda i : re.sub('[0-9]+','[NUM]',i))\r\n",
        "val_data['Total']=val_data['Total'].apply(lambda i : re.sub('[0-9]+','[NUM]',i))\r\n",
        "test_data['Total']=test_data['Total'].apply(lambda i : re.sub('[0-9]+','[NUM]',i))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukH8Ghocaw79"
      },
      "source": [
        "# Tokenizer 학습 시킬 txt 만들기\r\n",
        "train_tokenizer_text = open('./train_tokenizer.txt','w',encoding='utf-8')\r\n",
        "for i in train_data['Total']:\r\n",
        "    t=''\r\n",
        "    for j in i.split('.'):\r\n",
        "        train_tokenizer_text.write(j.strip()+'\\n') "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzGx2PuReydx"
      },
      "source": [
        "# WordPieceTokenizer Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lY0ogbdIEOl"
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer\r\n",
        "# 앞서 제작한 텍스트 파일 활용해 토크나이저 훈련\r\n",
        "tokenizer = BertWordPieceTokenizer()\r\n",
        "corpus_file   = ['train_tokenizer.txt']  # data path\r\n",
        "vocab_size    = 8000 # vocab size\r\n",
        "limit_alphabet= 6000\r\n",
        "output_path   = 'hugging_%d'%(vocab_size)\r\n",
        "min_frequency = 3 # 3회 이상 등장한 pair만 등장함\r\n",
        "special_tokens=['[CLS]','[SEP]','[BOS]', '[EOS]','[UNK]','[PAD]','[MASK]','[NUM]']  # 스페셜 토큰"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI4XP4K7KFzu"
      },
      "source": [
        "# Then train it!\r\n",
        "tokenizer.train(files=corpus_file,\r\n",
        "               vocab_size=vocab_size,\r\n",
        "               min_frequency=min_frequency,  # 단어의 최소 발생 빈도, 3\r\n",
        "               limit_alphabet=limit_alphabet,\r\n",
        "               show_progress=True,\r\n",
        "               special_tokens=special_tokens\r\n",
        "               )\r\n",
        "\r\n",
        "# And finally save it somewhere\r\n",
        "tokenizer.save(\"./%s_%s.json\"%(str('bert_tokenizer'), vocab_size))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj_2Wy6qdl4g"
      },
      "source": [
        "# 적정 수준의 seq len를 위한 EDA    \r\n",
        "2048수준으로 상정  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRzYq1lCcnqt"
      },
      "source": [
        "train_data['X']=train_data['Total'].apply(lambda i : tokenizer.encode(i).ids)\r\n",
        "train_data['len']=train_data['X'].apply(lambda i : len(i))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJFrEgKguJs0",
        "outputId": "cf0826c7-6195-49d8-9273-869f28ac56dd"
      },
      "source": [
        "np.percentile(train_data['len'].values,[50,75,95,99]) # 628.  , 1053.  , 2053.  , 3586.12"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 628.  , 1053.  , 2053.  , 3586.12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pIIRAAjjkvO",
        "outputId": "bcb726ed-55aa-427b-a872-cb28cf8d08a5"
      },
      "source": [
        "np.percentile(train_data.loc[train_data['damage']==1,'len'].values,[50,75,95,99]) # 681.  , 1019.  , 1651.1 , 2853.42\r\n",
        "# 2048 수준으로 해서 진행"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 681.  , 1019.  , 1651.1 , 2853.42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcErQ_x9mCJr",
        "outputId": "07ad8d96-9b29-4a50-ae31-25bbf9cfb7bb"
      },
      "source": [
        "(train_data.loc[train_data['damage']==1,'len']<2046).sum()/len(train_data.loc[train_data['damage']==1]) # 97.3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9734693877551021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-k7zFMvXHvZ"
      },
      "source": [
        "# VAE 용 data 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPLCQNiknik8"
      },
      "source": [
        "class Config(dict): \r\n",
        "    __getattr__ = dict.__getitem__\r\n",
        "    __setattr__ = dict.__setitem__\r\n",
        "config = Config({'n_layers': 2, 'n_head': 4, 'bidirectional':True,'embedding_dim': 128, 'd_model': 128, 'latent_dim': 64, 'hidden_dim': 128*4, 'seq_len': 2048, 'batch_size': 8, 'dropout': 0.1, 'max_len': 9999,'n_vocab':8000})"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k58NvK-iguC7"
      },
      "source": [
        "# tokenizer\r\n",
        "tokenizer = Tokenizer.from_file(\"./bert_tokenizer_%s.json\"%(config.n_vocab))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHMutRPCnPOU"
      },
      "source": [
        "config['padding_idx']=tokenizer.token_to_id('[PAD]')\r\n",
        "config['eos_idx']=tokenizer.token_to_id('[EOS]')\r\n",
        "config['bos_idx']=tokenizer.token_to_id('[BOS]')\r\n",
        "config['unk_idx']=tokenizer.token_to_id('[UNK]')\r\n",
        "config['mask_idx']=tokenizer.token_to_id('[MASK]')\r\n",
        "config['cls_idx']=tokenizer.token_to_id('[CLS]')\r\n",
        "config['num_idx']=tokenizer.token_to_id('[NUM]')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZZWv2GBZUWy"
      },
      "source": [
        "# 피해인 데이터만 선택\r\n",
        "train_data = train_data.loc[train_data['damage']==1,:]\r\n",
        "val_data = val_data.loc[val_data['damage']==1,:]\r\n",
        "test_data = test_data.loc[test_data['damage']==1,:]\r\n",
        "train_data['tokenized']=('[BOS]'+train_data['Total']+'[EOS]').apply(lambda i : tokenizer.encode(i).ids)\r\n",
        "val_data['tokenized']=('[BOS]'+val_data['Total']+'[EOS]').apply(lambda i : tokenizer.encode(i).ids)\r\n",
        "test_data['tokenized']=('[BOS]'+test_data['Total']+'[EOS]').apply(lambda i : tokenizer.encode(i).ids)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVcU8I1aldUM"
      },
      "source": [
        "def padding(sentence):\r\n",
        "    '''\r\n",
        "    ids padded\r\n",
        "    '''\r\n",
        "    if len(sentence)>config.seq_len:\r\n",
        "        result = sentence[:config.seq_len-1]\r\n",
        "        result.append(config.eos_idx)\r\n",
        "    elif len(sentence)<config.seq_len:\r\n",
        "        result = sentence\r\n",
        "        result.extend([config.padding_idx]*(config.seq_len-len(sentence))) \r\n",
        "    else:\r\n",
        "        result = sentence       \r\n",
        "    return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzC-mRiQdTM3"
      },
      "source": [
        "# padding 씌우기\r\n",
        "train_data['src']=train_data['tokenized'].apply(lambda i : padding(i))\r\n",
        "val_data['src']=val_data['tokenized'].apply(lambda i : padding(i))\r\n",
        "test_data['src']=test_data['tokenized'].apply(lambda i : padding(i))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywkNQ6hCiZAR",
        "outputId": "a0794b36-81cc-492c-dcb3-502e0a01052f"
      },
      "source": [
        "print(len(train_data)) # 980\r\n",
        "print(len(val_data)) # 136\r\n",
        "print(len(test_data)) # 183"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "980\n",
            "136\n",
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQzsPDBZdt3H"
      },
      "source": [
        "# TensorDataset으로 묶기\r\n",
        "train_data_set = TensorDataset(torch.LongTensor(train_data.src.tolist()))\r\n",
        "val_data_set = TensorDataset(torch.LongTensor(val_data.src.tolist()))\r\n",
        "test_data_set = TensorDataset(torch.LongTensor(test_data.src.tolist()))\r\n",
        "# DataLoader로 묶기\r\n",
        "train_loader = DataLoader(train_data_set,batch_size = config.batch_size)\r\n",
        "val_loader = DataLoader(val_data_set,batch_size = config.batch_size)\r\n",
        "test_loader = DataLoader(test_data_set,batch_size = config.batch_size)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TMX-SQmfvco"
      },
      "source": [
        "## models and tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RAl0_tYpRM3"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import copy\r\n",
        "import math\r\n",
        "\r\n",
        "def preprocessing(data, config, device, which):\r\n",
        "    '''\r\n",
        "    data : (bs, seq len)\r\n",
        "    src : BOS Sentence EOS -> CLS Sentence\r\n",
        "    tgt input : BOS Sentence\r\n",
        "    tgt output : Sentence EOS\r\n",
        "    '''\r\n",
        "    batch_size = data[0].size(0)\r\n",
        "    src = data[0][:,1:].to(device)\r\n",
        "    src = src.masked_fill(src.eq(config.eos_idx),config.padding_idx)\r\n",
        "    src = torch.cat([torch.full((batch_size,1),config.cls_idx,device=device),src],dim=-1).long()\r\n",
        "    tgt_input = data[0].to(device)\r\n",
        "    tgt_input = tgt_input.masked_fill(tgt_input.eq(config.eos_idx),config.padding_idx).long()\r\n",
        "    tgt_output = data[0][:,1:].to(device)\r\n",
        "    tgt_output = torch.cat([tgt_output,torch.full((batch_size,1),config.padding_idx,device=device)],dim=-1).long()\r\n",
        "    return batch_size, src, tgt_input, tgt_output\r\n",
        "\r\n",
        "def ce_kl(decoder_output, input, mu, log_var, kl_annealing, config): \r\n",
        "    '''\r\n",
        "    decoder output : batch size, seq_len, n_vocab\r\n",
        "    input : batch size, seq len\r\n",
        "    mu : batch size, latent_dim\r\n",
        "    log var : batch size, latent_dim\r\n",
        "    '''\r\n",
        "    # cross entropy : [bs, Class, d1,d2,.. dk] ~ [bs, Class]\r\n",
        "    CE=F.cross_entropy(decoder_output.transpose(1,2),input,ignore_index=config.padding_idx,reduction='sum') # batch size*seq_len에 대해서 나누지 않는다.\r\n",
        "    KL=-(0.5*(log_var+1.-log_var.exp()-mu.pow(2)).sum(-1)).sum()\r\n",
        "    CE = CE\r\n",
        "    KL = KL\r\n",
        "    return CE,KL\r\n",
        "    \r\n",
        "def calculate_loss(model,data_loader,config,device,which):\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "        total_loss = 0.\r\n",
        "        total_ce = 0.\r\n",
        "        total_kl = 0.\r\n",
        "        num = 0\r\n",
        "        for data in data_loader:\r\n",
        "            bs,src,tgt_input,tgt_output = preprocessing(data, config, device,which)\r\n",
        "            output,mu,log_var=model(src,tgt_input)\r\n",
        "            CE,KL=ce_kl(output,tgt_output,mu,log_var,1.,config)\r\n",
        "            total_ce+=CE.item()\r\n",
        "            total_kl+=KL.item()\r\n",
        "            num+=bs\r\n",
        "        avg_ce = total_ce/num\r\n",
        "        avg_kl = total_kl/num\r\n",
        "    return avg_ce, avg_kl\r\n",
        "\r\n",
        "def linear_anneal_function(step, total_step):\r\n",
        "    return min(1, (step-1)/total_step)\r\n",
        "\r\n",
        "def cycle_anneal_function(step, total_step, n_cycle = 4, ratio = 0.5):\r\n",
        "    t = (step-1)%(total_step//n_cycle)/(total_step/n_cycle)\r\n",
        "    f_t = t/ratio if t<=ratio else 1\r\n",
        "    return f_t\r\n",
        "\r\n",
        "def total_loss(decoder_output, input, mu, log_var, kl_annealing, config): \r\n",
        "    '''\r\n",
        "    decoder output : batch size,seq_len, n_vocab\r\n",
        "    input : batch size, seq len\r\n",
        "    mu : batch size, latent_dim\r\n",
        "    log var : batch size, latent_dim\r\n",
        "    '''\r\n",
        "    batch_size = decoder_output.size(0)\r\n",
        "    # cross entropy : [bs, Class, d1,d2,.. dk] ~ [bs, Class]\r\n",
        "    CE=F.cross_entropy(decoder_output.transpose(1,2),input,ignore_index=config.padding_idx,reduction='sum') # batch size*seq_len에 대해서 나누지 않는다.\r\n",
        "    KL=-(0.5*(log_var+1.-log_var.exp()-mu.pow(2)).sum(-1)).sum()\r\n",
        "    CE = CE/batch_size\r\n",
        "    KL = KL/batch_size\r\n",
        "    total=(CE+kl_annealing*KL)\r\n",
        "    return total,CE,KL\r\n",
        "\r\n",
        "class PositionalEncoding(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super(PositionalEncoding, self).__init__()\r\n",
        "        self.config=config\r\n",
        "        self.dropout = nn.Dropout(p=self.config.dropout)\r\n",
        "        self.pe = torch.zeros(config.max_len, config.d_model)\r\n",
        "        position = torch.arange(0, config.max_len, dtype=torch.float).unsqueeze(1)\r\n",
        "        div_term = torch.exp(torch.arange(0, config.d_model, 2).float() * (-math.log(10000.0) / config.d_model))\r\n",
        "        self.pe[:, 0::2] = torch.sin(position * div_term)\r\n",
        "        self.pe[:, 1::2] = torch.cos(position * div_term)\r\n",
        "        self.pe = self.pe.unsqueeze(0).transpose(0,1) # max len, d model -> 1, max len, d_model -> max len, 1, d_model\r\n",
        "    def forward(self, x):\r\n",
        "        '''\r\n",
        "        x shape : seq len, batch size, d model\r\n",
        "        '''\r\n",
        "        self.pe=self.pe.to(x.device)\r\n",
        "        x = x + self.pe[:x.size(0),:,:] # 후 항 shape : seq len, 1, d model\r\n",
        "        return self.dropout(x)\r\n",
        "\r\n",
        "class Transformer_Encoder_Base(nn.Module): # 현재 활용 중\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "        self.config=config\r\n",
        "        encoderlayer = nn.TransformerEncoderLayer(self.config.d_model,self.config.n_head,self.config.hidden_dim,self.config.dropout,activation='gelu')\r\n",
        "        self.embedding = nn.Embedding(self.config.n_vocab,self.config.d_model,padding_idx=self.config.padding_idx)\r\n",
        "        self.positional_embedding = PositionalEncoding(self.config)\r\n",
        "        self.Encoder = nn.TransformerEncoder(encoderlayer,self.config.n_layers)\r\n",
        "        self.dmodel2latent = nn.Linear(self.config.d_model, 2*self.config.latent_dim)\r\n",
        "\r\n",
        "    def subsquent_mask(self,src):\r\n",
        "        '''\r\n",
        "        src shape : src_seq_len, batch size\r\n",
        "        out put shape : src_seq_len, src_seq_len (mask씌울 부분을 -1e9, 아닌 부분을 0)\r\n",
        "        additive mask\r\n",
        "        '''\r\n",
        "        s=src.size(0)\r\n",
        "        mask=torch.triu(torch.ones((s,s)),1)==1\r\n",
        "        mask=mask.float().masked_fill(mask,-1e9) # True 인 부분을 -1e9로 채운다.\r\n",
        "        return mask\r\n",
        " \r\n",
        "    def padding_mask(self,src):\r\n",
        "        '''\r\n",
        "        src에서 padding idx와 같은 부분을 masking 씌운다.\r\n",
        "        src shape : seq_len, batch size\r\n",
        "        out put shape : batch size, seq_len (mask씌울 부분을 True, 아닌 부분을 FALSE)\r\n",
        "        # 나중에 TRUE인 부분에 -inf를 취한다(아마 softmax 이전! )\r\n",
        "        '''\r\n",
        "        out=src.eq(self.config.padding_idx)\r\n",
        "        return out.T \r\n",
        " \r\n",
        "    def reparametrization(self,mu,log_var):\r\n",
        "        '''\r\n",
        "        mu, log_var shape : batch size, latent_dim\r\n",
        "        e ~ N_k(0,I_k) shape : batch size, latent_dim\r\n",
        "        in paper  \r\n",
        "        cost(x_i) = -Eq(z|x_i)[log(p(x_i|z))]+KLD(q(z|x_i)|p(z))\r\n",
        "        Eq(z|x_i)[log(p(x_i|z))]=1/L(sigma(log(p(x_i|z_i,l)))) l = 1~L \"Monte Carlo Expectation estimate\r\n",
        "        z_i,l = mu + e_i,l * sigma \r\n",
        "        '''\r\n",
        "        sigma=torch.exp(0.5*log_var) # batch size, latent_dim\r\n",
        "        e=torch.randn_like(sigma,device=sigma.device) # batch size, latent_dim # strictly speaking, e shape : seq_len, batch size, L, latent dim\r\n",
        "        z=mu+sigma*e # z shape : batch size, latent_dim\r\n",
        "        return z\r\n",
        " \r\n",
        "    def forward(self, src):\r\n",
        "        # src : sentence\r\n",
        "        device=src.device\r\n",
        "        src = src.T # batch size, seq len  -> seq len, batch size\r\n",
        "        src_key_padding_mask = self.padding_mask(src).to(device)\r\n",
        "        \r\n",
        "        # encoder 부\r\n",
        "        # src [CLS] sentence\r\n",
        "        s1 = self.embedding(src)\r\n",
        "        src_out = s1 * math.sqrt(self.config.d_model)\r\n",
        "        src_out = self.positional_embedding(src_out) # seq len, batch size, d model\r\n",
        "        out = self.Encoder.forward(src_out, src_key_padding_mask=src_key_padding_mask) # seq len, batch size, d_model\r\n",
        "        # out shape : (seq len, batch size, d model)\r\n",
        "        \r\n",
        "        # z\r\n",
        "        CLS = out[0,:,:] # batch_size, d_model\r\n",
        "        z_para=self.dmodel2latent.forward(CLS).unsqueeze(-1).reshape(-1,self.config.latent_dim,2) # batch size, 2*latent_dim -> batch size, latent_dim, 2\r\n",
        "        mu,log_var=z_para[:,:,0],z_para[:,:,1] # batch size, latent_dim\r\n",
        "        z=self.reparametrization(mu,log_var) # batch size, latent_dim\r\n",
        "        return z, mu, log_var\r\n",
        "\r\n",
        "class Transformer_Decoder_Base(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "        self.config=config\r\n",
        "        encoderlayer = nn.TransformerEncoderLayer(self.config.d_model,self.config.n_head,self.config.hidden_dim,self.config.dropout,activation='gelu')\r\n",
        "        self.embedding = nn.Embedding(self.config.n_vocab,self.config.d_model,padding_idx=self.config.padding_idx)\r\n",
        "        self.positional_embedding = PositionalEncoding(self.config)\r\n",
        "        self.Decoder = nn.TransformerEncoder(encoderlayer,self.config.n_layers)\r\n",
        "        self.latent2dmodel = nn.Linear(self.config.latent_dim,self.config.d_model)\r\n",
        "        self.fc = nn.Linear(self.config.d_model,self.config.n_vocab)\r\n",
        "        \r\n",
        "    def subsquent_mask(self,src):\r\n",
        "        '''\r\n",
        "        src shape : src_seq_len, batch size\r\n",
        "        out put shape : src_seq_len, src_seq_len (mask씌울 부분을 -1e9, 아닌 부분을 0)\r\n",
        "        additive mask\r\n",
        "        '''\r\n",
        "        s=src.size(0)\r\n",
        "        mask=torch.triu(torch.ones((s,s)),1)==1\r\n",
        "        mask=mask.float().masked_fill(mask,-1e9) # True 인 부분을 -1e9로 채운다.\r\n",
        "        return mask\r\n",
        " \r\n",
        "    def padding_mask(self,src):\r\n",
        "        '''\r\n",
        "        src에서 padding idx와 같은 부분을 masking 씌운다.\r\n",
        "        src shape : seq_len, batch size\r\n",
        "        out put shape : batch size, seq_len (mask씌울 부분을 True, 아닌 부분을 FALSE)\r\n",
        "        # 나중에 TRUE인 부분에 -inf를 취한다(아마 softmax 이전! )\r\n",
        "        '''\r\n",
        "        out=src.eq(self.config.padding_idx)\r\n",
        "        return out.T \r\n",
        " \r\n",
        "    def forward(self, encoder_output, tgt): #, word_dropout=False):\r\n",
        "        '''\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        encoder_output : Shape (bs, latent_dim)\r\n",
        "            DESCRIPTION. z\r\n",
        "        tgt : Shape (bs, seq len, d model)\r\n",
        "            DESCRIPTION. [BOS] sentence\r\n",
        "        label : Shape (bs, )\r\n",
        "            DESCRIPTION. 1 - negative, 2 - neutral, 3 - positive\r\n",
        "        word_dropout : TYPE, optional\r\n",
        "            DESCRIPTION. The default is False.\r\n",
        "        '''\r\n",
        "        \r\n",
        "        device=tgt.device\r\n",
        "        tgt = tgt.T\r\n",
        "        tgt_key_padding_mask = self.padding_mask(tgt).to(device)\r\n",
        "        tgt_mask = self.subsquent_mask(tgt).to(device)\r\n",
        "        # memory z\r\n",
        "        memory_z=self.latent2dmodel(encoder_output) # batch size, d_model\r\n",
        "        memory_z = memory_z.unsqueeze(1).repeat(1,self.config.seq_len, 1).transpose(0,1).contiguous() # batch size, seq_len, d_model -> seq_len, batch size, d_model\r\n",
        "                \r\n",
        "        # tgt\r\n",
        "        tgt_input = tgt\r\n",
        "        t1 = self.embedding(tgt_input) \r\n",
        "        tgt_out = t1 * math.sqrt(self.config.d_model) # seq_len, batch size, d_model\r\n",
        "        tgt_out = self.positional_embedding(tgt_out) # seq_len, batch size, d model\r\n",
        "        tgt_output = self.Decoder.forward(src=tgt_out,mask=tgt_mask,src_key_padding_mask=tgt_key_padding_mask)\r\n",
        "        # seq len, batch size, d model\r\n",
        "        \r\n",
        "        tgt_output = memory_z + tgt_output\r\n",
        "        output = self.fc(tgt_output) # seq_len, bs, d_model*2 -> seq_len, bs, n_vocab\r\n",
        "        return output.transpose(0,1)  # batch size, seq_len, n_vocab\r\n",
        " \r\n",
        "class VAE_Transformer(nn.Module):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__()\r\n",
        "        self.config=config\r\n",
        "        self.encoder = Transformer_Encoder_Base(config)\r\n",
        "        self.decoder = Transformer_Decoder_Base(config)\r\n",
        "        \r\n",
        "    def reparametrization(self,mu,log_var):\r\n",
        "        '''\r\n",
        "        mu, log_var shape : batch size, latent_dim\r\n",
        "        e ~ N_k(0,I_k) shape : batch size, latent_dim\r\n",
        "        in paper  \r\n",
        "        cost(x_i) = -Eq(z|x_i)[log(p(x_i|z))]+KLD(q(z|x_i)|p(z))\r\n",
        "        Eq(z|x_i)[log(p(x_i|z))]=1/L(sigma(log(p(x_i|z_i,l)))) l = 1~L \"Monte Carlo Expectation estimate\r\n",
        "        z_i,l = mu + e_i,l * sigma \r\n",
        "        '''\r\n",
        "        sigma=torch.exp(0.5*log_var) # batch size, latent_dim\r\n",
        "        e=torch.randn_like(sigma,device=sigma.device) # batch size, latent_dim # strictly speaking, e shape : seq_len, batch size, L, latent dim\r\n",
        "        z=mu+sigma*e # z shape : batch size, latent_dim\r\n",
        "        return z\r\n",
        " \r\n",
        "    def forward(self, src, tgt):#, word_dropout=False):\r\n",
        "        # src : sentence\r\n",
        "        # tgt input : [BOS] sentence\r\n",
        "        # tgt output  : sentence [SEP]\r\n",
        "        \r\n",
        "        memory_z, mu, log_var = self.encoder.forward(src)\r\n",
        "        output = self.decoder.forward(memory_z,tgt)#,word_dropout)\r\n",
        "        return output, mu, log_var\r\n",
        "\r\n",
        "    def generation(self, method, device, beam_width = 5, alpha = 0.5, beta = 1):\r\n",
        "        '''\r\n",
        "        generation - greedy, beam search\r\n",
        "        '''\r\n",
        "        max_length = self.config.seq_len\r\n",
        "        \r\n",
        "        if method == 'greedy':\r\n",
        "            with torch.no_grad():\r\n",
        "                length = 0\r\n",
        "                z = torch.randn((self.config.batch_size, self.config.latent_dim),device = device)\r\n",
        "                bs = z.size(0)\r\n",
        "                result=torch.full((bs,1),self.config.bos_idx,device = device) #  bs\r\n",
        "                while length < max_length-1: # -1 : because of eos token\r\n",
        "                    tgt = torch.full((bs,self.config.seq_len), self.config.padding_idx, device = device) # batch size, seq len\r\n",
        "                    tgt[:,:length+1]=result\r\n",
        "                    ### [[bos pad pad ... pad],[bos pad pad ... pad],...,[bos pad pad ... pad]] 로 ######\r\n",
        "                    output = self.decoder.forward(z, tgt)# bs, seq_len, n_vocab\r\n",
        "                    appending = output[:,length,:].argmax(-1).unsqueeze(-1) # bs -> bs,1\r\n",
        "                    result = torch.hstack([result, appending])\r\n",
        "                    length+=1\r\n",
        "            return result\r\n",
        "        \r\n",
        "        if method == 'top_k':\r\n",
        "            with torch.no_grad():\r\n",
        "                length = 0\r\n",
        "                z = torch.randn((self.config.batch_size, self.config.latent_dim),device=device)\r\n",
        "                bs = z.size(0)\r\n",
        "                result=torch.full((bs,1),self.config.bos_idx,device = device) #  bs\r\n",
        "                while length < max_length-1:\r\n",
        "                    tgt = torch.full((bs,self.config.seq_len),self.config.padding_idx,device = device) # batch size, seq len\r\n",
        "                    tgt[:,:length+1]=result\r\n",
        "                    ### eos pad pad ... pad 로 ######\r\n",
        "                    output = self.decoder.forward(z, tgt) # batch size, seq_len, n_vocab\r\n",
        "                    appending = output[:,length,:]# batch size, n_vocab\r\n",
        "                    filtered_logits = top_k_filtering(appending,topk)\r\n",
        "                    probs = F.softmax(filtered_logits/t, dim=-1) # t : temperature\r\n",
        "                    next_token = torch.multinomial(probs,1) # batch size, 1\r\n",
        "                    result = torch.hstack([result, next_token])\r\n",
        "                    length+=1\r\n",
        "            return result\r\n",
        "\r\n",
        "        if method == 'beamsearch':\r\n",
        "            with torch.no_grad():\r\n",
        "                z = torch.randn((self.config.batch_size, self.config.latent_dim),device = device)\r\n",
        "                # batch size, seq_len, d_model -> seq_len, batch size, d_model\r\n",
        "                bs = z.size(0)\r\n",
        "                device = z.device\r\n",
        "                Batch_sequences=[]\r\n",
        "                for b in range(bs): # batch 별로\r\n",
        "                    length = 0\r\n",
        "                    batch_sequences=[]\r\n",
        "                    sequences = [[[self.config.bos_idx],0.0]] # beam width, sentence, log prob\r\n",
        "                    while length < max_length-1: # because of eos token\r\n",
        "                        all_candidates=[]\r\n",
        "                        for i in range(len(sequences)): # beam_width\r\n",
        "                            seq, score = sequences[i] # sequence and score\r\n",
        "                            tgt = torch.full((1, self.config.seq_len), self.config.padding_idx, device = device) # 1, seq len <- batch 별로 하니깐\r\n",
        "                            result = torch.LongTensor(seq).unsqueeze(0).to(device) # 1, seq len\r\n",
        "                            tgt[:,:length+1]=result\r\n",
        "                            ### sos pad pad ... pad 로 ######\r\n",
        "                            output = self.decoder.forward(z[b].unsqueeze(0),tgt) # 1, seq_len, n_vocab\r\n",
        "                            appending = output[:,length,:] # batch size, n_vocab\r\n",
        "                            appending = F.softmax(appending,-1) # 확률로 변환 bs, n_vocab\r\n",
        "                            penalty = ((1+length)/(1+beta))**alpha\r\n",
        "                            for j in range(self.config.n_vocab):\r\n",
        "                                candidate = [seq+[j], score+penalty*math.log(appending[0][j])] # 0 : batch 별로 하기에\r\n",
        "                                all_candidates.append(candidate)\r\n",
        "                        ordered = sorted(all_candidates, key = lambda t : t[1], reverse = True) # beam width * n_vocab 중에서 가장 작은 값 top beam width개\r\n",
        "                        sequences = ordered[:beam_width]\r\n",
        "                        length+=1\r\n",
        "                        batch_sequences.append(sequences)\r\n",
        "                    Batch_sequences.append(batch_sequences)\r\n",
        "            return Batch_sequences "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYCUjXZ7pZhX"
      },
      "source": [
        "def train(which, ds, epochs, annealing_strategy, device, k):\r\n",
        "    '''\r\n",
        "    which : model type\r\n",
        "    ds : dataset\r\n",
        "    epochs : epochs\r\n",
        "    annealing_strategy : annealing_strategy\r\n",
        "    device : device\r\n",
        "    k : kl annealing step when it becomes 1. or freq\r\n",
        "    '''\r\n",
        "    if which == 'transformer':\r\n",
        "        model = VAE_Transformer(config) \r\n",
        "    model.to(device)\r\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\r\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=k, T_mult=1, eta_min=1e-7, last_epoch=-1, verbose=False)\r\n",
        "    epochs = epochs\r\n",
        "    annealing_strategy = annealing_strategy\r\n",
        "    description = 'dataset_%s__model_%s__anneal_%s(%s)'%(ds, which, annealing_strategy, k)\r\n",
        "    #########################################################\r\n",
        "                        # train\r\n",
        "    \r\n",
        "    #########################################################\r\n",
        "    start_time = time.time()\r\n",
        "    step = 0\r\n",
        "    # train epoch\r\n",
        "    TOTAL_loss = []\r\n",
        "    CE_loss = []\r\n",
        "    KL_loss = []\r\n",
        "    kl_anneal = []\r\n",
        "    # val epoch\r\n",
        "    VAL_TOTAL_loss = []\r\n",
        "    VAL_CE_loss = []\r\n",
        "    VAL_KL_loss = []\r\n",
        "    # min value를 위함\r\n",
        "    check_count = 0\r\n",
        "    check_model = None\r\n",
        "    min_value_recon = None\r\n",
        "    min_value_epoch = None\r\n",
        "    for epoch in tqdm(range(1,1+epochs),desc='epoch',mininterval=60):\r\n",
        "        model.train()\r\n",
        "        Total_loss=0\r\n",
        "        Total_cross_entropy=0\r\n",
        "        Total_kl=0\r\n",
        "        num=0\r\n",
        "        for data in train_loader:\r\n",
        "            step += 1\r\n",
        "            optimizer.zero_grad()\r\n",
        "            # src : batch size, seq len\r\n",
        "            batch_size,src,tgt_input,tgt_output = preprocessing(data, config, device,which)\r\n",
        "            if annealing_strategy == 'linear':\r\n",
        "                anneal = linear_anneal_function(step, len(train_loader)*k)\r\n",
        "            elif annealing_strategy == 'cycle':\r\n",
        "                anneal = cycle_anneal_function(step, len(train_loader)*epochs, n_cycle = epochs//k, ratio = 0.5)    \r\n",
        "            else:\r\n",
        "                anneal = annealing_strategy\r\n",
        "            output,mu,log_var = model.forward(src,tgt_input)\r\n",
        "            CE,KL=ce_kl(output, tgt_output,mu,log_var,anneal,config)\r\n",
        "            loss  = CE + KL * anneal\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            Total_cross_entropy+=CE.item()\r\n",
        "            Total_kl+=KL.item()\r\n",
        "            num+=batch_size\r\n",
        "        CE_loss.append(Total_cross_entropy/num)\r\n",
        "        KL_loss.append(Total_kl/num)\r\n",
        "        kl_anneal.append(anneal) # epoch마다의 anneal임.\r\n",
        "        scheduler.step()\r\n",
        "    #########################################################\r\n",
        "        \r\n",
        "                            # validation\r\n",
        "        \r\n",
        "    #########################################################\r\n",
        "        with torch.no_grad():\r\n",
        "            model.eval()\r\n",
        "            Val_CE=0\r\n",
        "            Val_KL=0\r\n",
        "            m=0\r\n",
        "            \r\n",
        "            for data in val_loader:\r\n",
        "                batch_size,src,tgt_input,tgt_output = preprocessing(data, config, device,which)\r\n",
        "                output,mu,log_var=model(src,tgt_input)\r\n",
        "                CE,KL=ce_kl(output,tgt_output,mu,log_var,1.,config)\r\n",
        "                Val_CE+=CE.item()\r\n",
        "                Val_KL+=KL.item()\r\n",
        "                m+=batch_size\r\n",
        "            VAL_CE_loss.append(Val_CE/m)\r\n",
        "            VAL_KL_loss.append(Val_KL/m)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "            if min_value_recon is None:\r\n",
        "                min_value_epoch = copy.deepcopy(epoch)\r\n",
        "                min_value_recon = copy.deepcopy(Val_CE/m)\r\n",
        "                min_value_KL = copy.deepcopy(Val_KL/m)\r\n",
        "                check_model = copy.deepcopy(model.state_dict())\r\n",
        "                \r\n",
        "            current_recon = Val_CE/m\r\n",
        "            current_kl = Val_KL/m\r\n",
        "            if current_recon - min_value_recon < 0:\r\n",
        "                min_value_epoch = copy.deepcopy(epoch)\r\n",
        "                min_value_recon = copy.deepcopy(current_recon)\r\n",
        "                min_value_KL = copy.deepcopy(current_kl)\r\n",
        "                check_model = copy.deepcopy(model.state_dict())\r\n",
        "                check_count = 0\r\n",
        "            else:\r\n",
        "                if check_count == 4:\r\n",
        "                    print('early stop')\r\n",
        "                    break\r\n",
        "                else:\r\n",
        "                    check_count+=1\r\n",
        "\r\n",
        "        if epoch % 5 ==0:\r\n",
        "            print('-------------------------TRAIN----------------------------')\r\n",
        "            print(\"| Epoch : %d | |\" % (epoch)) \r\n",
        "            print(\"| Reconstruction Error : %.3f | KL divergence : %.3f | KL annealing : %.3f |\"%(Total_cross_entropy/num\\\r\n",
        "                                                                                                            ,Total_kl/num,anneal\\\r\n",
        "                                                                                                            ))\r\n",
        "            \r\n",
        "            print('----------------------------------------------------------')    \r\n",
        "            print('--------------------------VAL-----------------------------')\r\n",
        "            print(\"| Reconstruction Error : %.3f | KL divergence : %.3f |\"%(Val_CE/m,Val_KL/m))\r\n",
        "            print('----------------------------------------------------------')    \r\n",
        "    result = df()\r\n",
        "    result['train_recon']=CE_loss\r\n",
        "    result['train_kl']=KL_loss\r\n",
        "    result['train_kl_anneal']=kl_anneal\r\n",
        "    result['val_recon']=VAL_CE_loss\r\n",
        "    result['val_kl']=VAL_KL_loss\r\n",
        "    result.to_csv('./epoch_%s.csv'%(description))\r\n",
        "    torch.save(check_model, './min_recon_model_epoch%d'%min_value_epoch)\r\n",
        "    #return result"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsYAbFYGB4GO"
      },
      "source": [
        "# VAE Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxaR2lQzi5gS"
      },
      "source": [
        "os.chdir('./data_augmentation')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhAtdnr8qIp2",
        "outputId": "e3a370be-6814-45a6-973b-0b2cc12e30df"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "k = 10\r\n",
        "experiment = [('transformer','ptb',100,'cycle',k)]\r\n",
        "torch.cuda.empty_cache()\r\n",
        "for ex in experiment:\r\n",
        "    try:\r\n",
        "        os.mkdir('./lr_1e-3_%s'%str(ex))\r\n",
        "    except:\r\n",
        "        print()\r\n",
        "    os.chdir('./lr_1e-3_%s'%str(ex))\r\n",
        "    which, ds, epochs, annealing_strategy, k = ex\r\n",
        "    now = time.time()\r\n",
        "    train(which, ds, epochs, annealing_strategy, device, k)\r\n",
        "    torch.cuda.empty_cache()    \r\n",
        "    os.chdir('..')\r\n",
        "    print(time.time()-now)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:   3%|▎         | 3/100 [01:40<43:50, 27.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------TRAIN----------------------------\n",
            "| Epoch : 5 | |\n",
            "| Reconstruction Error : 4361.824 | KL divergence : 28.997 | KL annealing : 0.998 |\n",
            "----------------------------------------------------------\n",
            "--------------------------VAL-----------------------------\n",
            "| Reconstruction Error : 4811.388 | KL divergence : 29.311 |\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:   9%|▉         | 9/100 [04:20<41:05, 27.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------TRAIN----------------------------\n",
            "| Epoch : 10 | |\n",
            "| Reconstruction Error : 3950.135 | KL divergence : 26.501 | KL annealing : 1.000 |\n",
            "----------------------------------------------------------\n",
            "--------------------------VAL-----------------------------\n",
            "| Reconstruction Error : 4623.431 | KL divergence : 28.666 |\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  15%|█▌        | 15/100 [06:46<38:20, 27.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------TRAIN----------------------------\n",
            "| Epoch : 15 | |\n",
            "| Reconstruction Error : 3576.857 | KL divergence : 27.931 | KL annealing : 0.998 |\n",
            "----------------------------------------------------------\n",
            "--------------------------VAL-----------------------------\n",
            "| Reconstruction Error : 4425.353 | KL divergence : 29.028 |\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  18%|█▊        | 18/100 [08:20<36:59, 27.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------TRAIN----------------------------\n",
            "| Epoch : 20 | |\n",
            "| Reconstruction Error : 3348.786 | KL divergence : 25.570 | KL annealing : 1.000 |\n",
            "----------------------------------------------------------\n",
            "--------------------------VAL-----------------------------\n",
            "| Reconstruction Error : 4380.991 | KL divergence : 28.043 |\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  21%|██        | 21/100 [09:40<35:37, 27.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "early stop\n",
            "656.0571076869965\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}