{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[기상청][W2V][LSTM][Weight]",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZhPKJACXNUl",
        "outputId": "b09c5b8b-1fe1-4f73-9018-0226e28bb524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install transformers\n",
        "! pip install konlpy\n",
        "! pip install kss"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 6.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=05fff829c7f3d9becd9d019e799b3f5ed33370408bbf3168b38a8e80dc3b3a37\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 55.1MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.5MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqswTNjuazIv",
        "outputId": "7fe0caaa-1534-49a3-9d90-6431a163d846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torchtext\n",
        "from google.colab import drive\n",
        "from konlpy.tag import Okt\n",
        "from torch.autograd import Variable, grad\n",
        "from transformers import AdamW,get_linear_schedule_with_warmup,get_constant_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import pickle\n",
        "import kss\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('./gdrive/My Drive/기상청')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txu7KNnBACZf"
      },
      "source": [
        "# pretrained된 w2v model 불러오기\n",
        "vectors=torchtext.vocab.Vectors('wv_128',cache='./')"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq19MnTiPQ3w"
      },
      "source": [
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx4adeEbPSN2"
      },
      "source": [
        "config=Config({'embedding_dim':128,'hidden_dim':256,'seq_len':512,'batch_size':32,'dense_dim':32,'dropout':0.3,'num_layers':1,'padding_idx':1})"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgplJHl4Iroh"
      },
      "source": [
        "# 1 preprocessing\n",
        "# torchtext를 활용하면 한방에(tokenize,wordembedding,padding ...)\n",
        "# SOS,EOS,padding,fix_len : 50\n",
        "import torchtext\n",
        "# Field 정의 ~ 빅데이터 시스템 및 계산에서 공부한 column과 비슷\n",
        "# Text <- padding 하지 말아라\n",
        "Text=torchtext.data.Field(sequential=True,use_vocab=True,batch_first=True,tokenize=lambda i : okt.morphs(i,stem=True),lower=False,fix_length=config.seq_len,init_token='<SOS>',eos_token='<EOS>',pad_token='<PAD>',unk_token='<UNK>')\n",
        "Target=torchtext.data.Field(sequential=False,use_vocab=False,batch_first=True,is_target=True)\n",
        "\n",
        "# Data 정의\n",
        "Train_data=torchtext.data.TabularDataset('./train_data.csv',format='csv',fields=[('total',Text),('피해',Target)],\n",
        "                                           skip_header=True)\n",
        "Test_data=torchtext.data.TabularDataset('./test_data.csv',format='csv',fields=[('total',Text),('피해',Target)],\n",
        "                                           skip_header=True)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrKdFc2cREqz"
      },
      "source": [
        "# load embeddings using torchtext\n",
        "Text.build_vocab(Train_data,min_freq=3,vectors=vectors)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyacwwJYRL2A"
      },
      "source": [
        "# data loader\n",
        "train_loader=torchtext.data.Iterator(Train_data,batch_size=config.batch_size)\n",
        "test_loader=torchtext.data.Iterator(Test_data,batch_size=config.batch_size)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43xbC3hOZI3W"
      },
      "source": [
        "class lstm_model(nn.Module):\n",
        "    def __init__(self,config,vectors):\n",
        "        super().__init__()\n",
        "        self.config=config\n",
        "        self.embedding=nn.Embedding.from_pretrained(vectors,freeze=False,padding_idx=self.config.padding_idx)\n",
        "        self.lstm=nn.LSTM(self.config.embedding_dim,self.config.hidden_dim,bidirectional=True,batch_first=True)\n",
        "        self.classifier=nn.Sequential(nn.Linear(2*self.config.hidden_dim,self.config.dense_dim),nn.ReLU(),nn.Linear(self.config.dense_dim,2))\n",
        "        # classifier 부분의 마지막 단은, 어차피 cross entropy를 활용할 것이기 때문에 굳이 sigmoid를 취하지 않아도 된다.\n",
        "        self.dropout=nn.Dropout(self.config.dropout)\n",
        "    def forward(self,input):\n",
        "        '''\n",
        "        input shape : batch size, seq_len \n",
        "        '''\n",
        "        embed=self.embedding(input) # batch size, seq_len, embedding_dim\n",
        "        embed=self.dropout(embed)\n",
        "        input,(hidden,cell)=self.lstm(embed) # input shape  :batch size, seq len, hidden dim\n",
        "        input=input[:,-1,:] # batch size, 2*hidden dim\n",
        "        pred=self.classifier(input) # pred shape : batch size, 2\n",
        "        return pred"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCrnlCnlZK11"
      },
      "source": [
        "# train\n",
        "import time\n",
        "device = 'cuda:0'\n",
        "model = lstm_model(config,Text.vocab.vectors)\n",
        "model.to(device)\n",
        "# Criterion\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1,0.9]).cuda())\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-4, # 학습률\n",
        "                  eps = 1e-8, # 0으로 나누는 것을 막아준다.\n",
        "                  weight_decay=0.3\n",
        "                )\n",
        "# 에폭수\n",
        "epochs = 100"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxByxZzcq2gh"
      },
      "source": [
        "# 시간 표시 함수\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NZNOwb8ZMel",
        "outputId": "27801ad7-3f02-45c5-d674-9b54e446be75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "start_time=time.time()\n",
        "for epoch in range(1,epochs+1):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    total_acc=0\n",
        "    for batch in train_loader:\n",
        "        x=batch.total.to(device)\n",
        "        y=batch.피해.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss=criterion(pred,y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1) \n",
        "        optimizer.step()   \n",
        "        total_loss+=loss.item()\n",
        "        acc=(pred.argmax(-1)==y).float().mean()\n",
        "        total_acc+=acc\n",
        "    if epoch%10==0:\n",
        "        print(\"EPOCH : %d\"%epoch)\n",
        "        print(\"| TRAIN_LOSS : %.4f | TRAIN_ACC : %.4f | Eplased time : %s\"\\\n",
        "            %(total_loss/len(train_loader),total_acc/len(train_loader),format_time(time.time()-start_time)))\n",
        "        \n",
        "\n",
        "            "
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH : 10\n",
            "| TRAIN_LOSS : 0.3491 | TRAIN_ACC : 0.9021 | Eplased time : 0:01:52\n",
            "EPOCH : 20\n",
            "| TRAIN_LOSS : 0.3163 | TRAIN_ACC : 0.9211 | Eplased time : 0:03:44\n",
            "EPOCH : 30\n",
            "| TRAIN_LOSS : 0.2596 | TRAIN_ACC : 0.9316 | Eplased time : 0:05:35\n",
            "EPOCH : 40\n",
            "| TRAIN_LOSS : 0.2500 | TRAIN_ACC : 0.9316 | Eplased time : 0:07:25\n",
            "EPOCH : 50\n",
            "| TRAIN_LOSS : 0.2874 | TRAIN_ACC : 0.9222 | Eplased time : 0:09:15\n",
            "EPOCH : 60\n",
            "| TRAIN_LOSS : 0.2881 | TRAIN_ACC : 0.9157 | Eplased time : 0:11:05\n",
            "EPOCH : 70\n",
            "| TRAIN_LOSS : 0.2935 | TRAIN_ACC : 0.9286 | Eplased time : 0:12:54\n",
            "EPOCH : 80\n",
            "| TRAIN_LOSS : 0.3155 | TRAIN_ACC : 0.9193 | Eplased time : 0:14:44\n",
            "EPOCH : 90\n",
            "| TRAIN_LOSS : 0.3371 | TRAIN_ACC : 0.9127 | Eplased time : 0:16:34\n",
            "EPOCH : 100\n",
            "| TRAIN_LOSS : 0.3202 | TRAIN_ACC : 0.9074 | Eplased time : 0:18:22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-uC6jtIwB_j"
      },
      "source": [
        "## TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QblYnbhFwDpu",
        "outputId": "7e2125ef-23d9-4985-bb2c-68285d52459c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.eval()\n",
        "total_loss=0\n",
        "total_acc=0\n",
        "Pred=[]\n",
        "TruE=[]\n",
        "for batch in train_loader:\n",
        "    x=batch.total.to(device)\n",
        "    y=batch.피해.to(device)\n",
        "    pred = model(x)\n",
        "    loss=criterion(pred,y)\n",
        "    total_loss+=loss.item()\n",
        "    acc=(pred.argmax(-1)==y).float().mean()\n",
        "    total_acc+=acc\n",
        "    Pred.extend(pred.argmax(-1).cpu().tolist())\n",
        "    TruE.extend(y.cpu().tolist())\n",
        "\n",
        "print(\"| TRAIN_LOSS : %.4f | TRAIN_ACC : %.4f |\"\\\n",
        "    %(total_loss/len(train_loader),total_acc/len(train_loader)))   \n",
        "print(classification_report(TruE,Pred))     \n",
        "\n",
        "model.eval()\n",
        "total_loss=0\n",
        "total_acc=0\n",
        "Pred=[]\n",
        "TruE=[]\n",
        "for batch in test_loader:\n",
        "    x=batch.total.to(device)\n",
        "    y=batch.피해.to(device)\n",
        "    pred = model(x)\n",
        "    loss=criterion(pred,y)\n",
        "    total_loss+=loss.item()\n",
        "    acc=(pred.argmax(-1)==y).float().mean()\n",
        "    total_acc+=acc\n",
        "    Pred.extend(pred.argmax(-1).cpu().tolist())\n",
        "    TruE.extend(y.cpu().tolist())\n",
        "\n",
        "print(\"| TEST_LOSS : %.4f | TEST_ACC : %.4f |\"\\\n",
        "    %(total_loss/len(test_loader),total_acc/len(test_loader)))          \n",
        "print(classification_report(TruE,Pred))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| TRAIN_LOSS : 0.3025 | TRAIN_ACC : 0.9138 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.95      6074\n",
            "           1       0.69      0.86      0.76      1169\n",
            "\n",
            "    accuracy                           0.91      7243\n",
            "   macro avg       0.83      0.89      0.86      7243\n",
            "weighted avg       0.93      0.91      0.92      7243\n",
            "\n",
            "| TEST_LOSS : 0.9694 | TEST_ACC : 0.8493 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91       673\n",
            "           1       0.54      0.58      0.56       132\n",
            "\n",
            "    accuracy                           0.85       805\n",
            "   macro avg       0.73      0.74      0.74       805\n",
            "weighted avg       0.86      0.85      0.85       805\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31hxK3DlozuJ"
      },
      "source": [
        "torch.save(model.stat6e_dict(),'./model_w2v_lstm_2')"
      ],
      "execution_count": 229,
      "outputs": []
    }
  ]
}